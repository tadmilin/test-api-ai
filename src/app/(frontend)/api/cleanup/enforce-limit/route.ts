import { NextResponse } from 'next/server'
import { getPayload } from 'payload'
import config from '@payload-config'
import { del } from '@vercel/blob'

export const runtime = 'nodejs'
export const dynamic = 'force-dynamic'

const MAX_JOBS = 50

/**
 * POST /api/cleanup/enforce-limit
 * ‡∏•‡∏ö jobs ‡πÄ‡∏Å‡πà‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡∏¥‡∏ô 50 jobs (FIFO)
 */
export async function POST() {
  try {
    console.log('üîç [Cleanup] Checking job count...')
    const payload = await getPayload({ config })

    // ‡∏ô‡∏±‡∏ö jobs ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    const { totalDocs } = await payload.find({
      collection: 'jobs',
      limit: 0,
    })

    console.log(`üìä [Cleanup] Total jobs: ${totalDocs}`)

    if (totalDocs <= MAX_JOBS) {
      console.log(`‚úÖ [Cleanup] Within limit (${totalDocs}/${MAX_JOBS})`)
      return NextResponse.json({ 
        success: true, 
        message: 'Within limit',
        totalJobs: totalDocs,
        limit: MAX_JOBS,
        deleted: 0,
      })
    }

    // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏ö
    const toDelete = totalDocs - MAX_JOBS
    console.log(`‚ö†Ô∏è [Cleanup] Over limit! Need to delete ${toDelete} jobs`)

    // ‡∏´‡∏≤ jobs ‡πÄ‡∏Å‡πà‡∏≤‡∏™‡∏∏‡∏î
    const oldJobs = await payload.find({
      collection: 'jobs',
      sort: 'createdAt', // ‡πÄ‡∏Å‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô
      limit: toDelete,
    })

    if (oldJobs.docs.length === 0) {
      console.log('‚ö†Ô∏è [Cleanup] No jobs found to delete')
      return NextResponse.json({ 
        success: true, 
        message: 'No jobs to delete',
        deleted: 0,
      })
    }

    console.log(`üóëÔ∏è  [Cleanup] Deleting ${oldJobs.docs.length} oldest jobs...`)

    let deletedCount = 0
    let blobDeletedCount = 0
    const errors: string[] = []

    for (const job of oldJobs.docs) {
      try {
        console.log(`\nüì¶ [Cleanup] Processing job ${job.id} (${job.productName || 'Untitled'})`)

        // ‚úÖ Step 1: ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå blob ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        const blobUrls: string[] = []

        // ‡∏£‡∏π‡∏õ enhanced
        if (job.enhancedImageUrls && Array.isArray(job.enhancedImageUrls)) {
          for (const img of job.enhancedImageUrls) {
            if (img.url && typeof img.url === 'string' && img.url.includes('blob.vercel-storage.com')) {
              blobUrls.push(img.url)
            }
          }
        }

        // Template
        if (job.templateUrl && typeof job.templateUrl === 'string' && job.templateUrl.includes('blob.vercel-storage.com')) {
          blobUrls.push(job.templateUrl)
        }

        console.log(`   Found ${blobUrls.length} blob files to delete`)

        // ‡∏•‡∏ö blob files
        for (const url of blobUrls) {
          try {
            await del(url)
            blobDeletedCount++
            console.log(`   ‚úÖ Deleted blob: ${url.substring(url.lastIndexOf('/') + 1)}`)
          } catch (blobError) {
            console.warn(`   ‚ö†Ô∏è Failed to delete blob ${url}:`, blobError)
            // ‡πÑ‡∏°‡πà throw error ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏≠‡∏≤‡∏à‡∏ñ‡∏π‡∏Å‡∏•‡∏ö‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß
          }
        }

        // ‚úÖ Step 2: ‡∏•‡∏ö job-logs ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
        try {
          const logs = await payload.find({
            collection: 'job-logs',
            where: {
              jobId: {
                equals: job.id,
              },
            },
          })

          if (logs.totalDocs > 0) {
            for (const log of logs.docs) {
              await payload.delete({
                collection: 'job-logs',
                id: log.id,
              })
            }
            console.log(`   ‚úÖ Deleted ${logs.totalDocs} job logs`)
          }
        } catch (logError) {
          console.warn(`   ‚ö†Ô∏è Failed to delete logs:`, logError)
        }

        // ‚úÖ Step 3: ‡∏•‡∏ö job record
        await payload.delete({
          collection: 'jobs',
          id: job.id,
        })

        deletedCount++
        console.log(`   ‚úÖ Job ${job.id} deleted successfully`)

      } catch (jobError) {
        const errorMsg = jobError instanceof Error ? jobError.message : 'Unknown error'
        console.error(`   ‚ùå Failed to delete job ${job.id}:`, errorMsg)
        errors.push(`Job ${job.id}: ${errorMsg}`)
      }
    }

    console.log(`\n‚úÖ [Cleanup] Complete!`)
    console.log(`   Jobs deleted: ${deletedCount}/${oldJobs.docs.length}`)
    console.log(`   Blob files deleted: ${blobDeletedCount}`)
    
    if (errors.length > 0) {
      console.warn(`   ‚ö†Ô∏è Errors encountered: ${errors.length}`)
    }

    // ‚úÖ Cleanup orphan template upscale predictions (stuck > 10 minutes)
    console.log(`\nüßπ [Cleanup] Checking for orphan template predictions...`)
    try {
      const tenMinutesAgo = new Date(Date.now() - 10 * 60 * 1000).toISOString()
      
      const orphanJobs = await payload.find({
        collection: 'jobs',
        where: {
          and: [
            {
              templateUpscalePredictionId: {
                exists: true,
              },
            },
            {
              updatedAt: {
                less_than: tenMinutesAgo,
              },
            },
          ],
        },
      })

      if (orphanJobs.docs.length > 0) {
        console.log(`   Found ${orphanJobs.docs.length} orphan template predictions`)
        
        for (const orphanJob of orphanJobs.docs) {
          await payload.update({
            collection: 'jobs',
            id: orphanJob.id,
            data: {
              templateUpscalePredictionId: null,
            } as any,
          })
          console.log(`   ‚úÖ Cleared orphan prediction from job ${orphanJob.id}`)
        }
      } else {
        console.log(`   ‚úÖ No orphan template predictions found`)
      }
    } catch (orphanError) {
      console.warn(`   ‚ö†Ô∏è Orphan cleanup failed:`, orphanError)
      // Don't fail the whole operation
    }

    return NextResponse.json({
      success: true,
      message: `Deleted ${deletedCount} old jobs`,
      deleted: deletedCount,
      blobsDeleted: blobDeletedCount,
      totalJobs: totalDocs,
      newTotal: totalDocs - deletedCount,
      limit: MAX_JOBS,
      errors: errors.length > 0 ? errors : undefined,
    })

  } catch (error) {
    console.error('‚ùå [Cleanup] Fatal error:', error)
    return NextResponse.json(
      { 
        success: false, 
        error: error instanceof Error ? error.message : 'Cleanup failed',
      },
      { status: 500 }
    )
  }
}

/**
 * GET /api/cleanup/enforce-limit
 * ‡∏î‡∏π‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ storage ‡πÅ‡∏•‡∏∞ cleanup
 */
export async function GET() {
  try {
    const payload = await getPayload({ config })

    // ‡∏ô‡∏±‡∏ö jobs ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    const { totalDocs } = await payload.find({
      collection: 'jobs',
      limit: 0,
    })

    // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì storage estimate (4.5 MB/job ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢)
    const estimatedStorageMB = Math.round(totalDocs * 4.5)
    const storagePercent = Math.round((estimatedStorageMB / 1024) * 100)

    // ‡πÄ‡∏ä‡πá‡∏Ñ orphan template predictions
    const orphanJobs = await payload.find({
      collection: 'jobs',
      where: {
        templateUpscalePredictionId: {
          exists: true,
        },
      },
      limit: 0,
    })

    // ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
    let status: 'healthy' | 'warning' | 'critical' = 'healthy'
    if (totalDocs > MAX_JOBS + 10) status = 'critical'
    else if (totalDocs > MAX_JOBS) status = 'warning'

    return NextResponse.json({
      success: true,
      totalJobs: totalDocs,
      limit: MAX_JOBS,
      usage: `${totalDocs}/${MAX_JOBS}`,
      usagePercent: Math.round((totalDocs / MAX_JOBS) * 100),
      estimatedStorageMB,
      storagePercent,
      orphanTemplatePredictions: orphanJobs.totalDocs,
      status,
      timestamp: new Date().toISOString(),
    })

  } catch (error) {
    console.error('‚ùå [Cleanup Status] Error:', error)
    return NextResponse.json(
      { 
        success: false, 
        error: error instanceof Error ? error.message : 'Failed to get status',
      },
      { status: 500 }
    )
  }
}
